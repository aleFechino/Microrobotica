{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c89a545-61e0-4f09-aa33-8c19ce20ca72",
   "metadata": {},
   "source": [
    "## Un modello matematico del testo in linguaggio naturale\n",
    "(linguaggio naturale è la lingua umana)\n",
    "\n",
    "* Questo modello ci aiuterà a capire come funzionano i **LLM** (Large Languege Model).\n",
    "* I LLM sono le reti neurali alla base dell'IA generativa.(reti neurali= replica un po' i neurali che abbiamo noi nel nostro cervello, i nostri neuroni sono collegati da psinapsi che apprendendo essi cambiano-> e i collegamenti fra precettoni viene tramite dei logaritmi che vanno a cambiare il valore dei collegamenti)\n",
    "* I LLM generano il testo mediante un processo detto **autoregressione**: quando forniamo un prompt all'IA generativa, il LLM genera la risposta **token** per **token**. (token=dividono in parti la conversazione fornita ai LLM)(autoregressione=generare qualcosa di nuovo a partire da quello che ha già generato prima, l'input che prende è il _contesto_ ed è l'insieme di quello detto dall'utente e quello risposto dal LLM). A ogni istante della generazione della risposta, LLM prende in input tutti i token del prompt e tutti i nuovi token che ha generato fino a quel momento.\n",
    "\n",
    "[applicazione scalabile significa che è in grado di fornire il servizio indipendetemente dal numero di accessi l'hardware e il software riesce a dare il servizio bene e gestendolo bene]\n",
    "[(Large Word Model) LWM-> sono ciò che stanno provando a sviluppare le grandi aziende, cercano che sia in grado di vivere nel mondo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb2c6d8c-10db-4d7f-ae0e-ef1de58233a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importazioni librerie\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c232e38-8202-440d-a0a6-c07941fa9b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text= file.read()\\nprint(text)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Caricamento input\n",
    "file= open(\"./sei_personaggi_in_cerca_dautore_Luigi_Pirandello.txt\", \"r\", encoding=\"utf-8\")\n",
    "'''text= file.read()\n",
    "print(text)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6a9e6f-338a-49e2-a80d-853a347ea842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Pre-processing\\ntext= text.replace(\"\\n\", \" \").lower()\\nfor _ in range(2):\\n    text=text.replace(\"  \", \" \")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Pre-processing\n",
    "text= text.replace(\"\\n\", \" \").lower()\n",
    "for _ in range(2):\n",
    "    text=text.replace(\"  \", \" \")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456491ce-b3b6-4908-853b-e1e16ef5085a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmarkov_dict={}\\nfor i, _ in enumerate(text[:-l_context]):  #scorre fino in fondo meno il numero di caratteri presi\\n    ngram=text[i:i+l_context] #devo prendere il numero di lettere deciso(ngramma è una sequenza di lette)\\n    #print(ngram)\\n    if ngram in markov_dict:\\n        markov_dict[ngram].append(text[i+l_context])\\n    else:\\n        markov_dict[ngram]=[text[i+l_context]]\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i nostri token sono sempre un carattere\n",
    "l_context=6\n",
    "'''\n",
    "markov_dict={}\n",
    "for i, _ in enumerate(text[:-l_context]):  #scorre fino in fondo meno il numero di caratteri presi\n",
    "    ngram=text[i:i+l_context] #devo prendere il numero di lettere deciso(ngramma è una sequenza di lette)\n",
    "    #print(ngram)\n",
    "    if ngram in markov_dict:\n",
    "        markov_dict[ngram].append(text[i+l_context])\n",
    "    else:\n",
    "        markov_dict[ngram]=[text[i+l_context]]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bfcd24a-5d48-479d-9099-eb2e7647734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 'r', 'r', 'r', 'r', 'r']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#markov_dict[\"sei pe\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa436c56-a319-40ac-89ec-4f7231fcea19",
   "metadata": {},
   "source": [
    "Il dizionario `markov_dict` è un modello matematicp del linguaggio naturale che ora usiamo per costruire una autoregressione Markoviano (Markov è un matemativo russo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2b9749-0c99-42ee-b6d8-48701c6aa2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nngram_0=\"sei pe\"\\nl_phrase=100\\nphrase=ngram_0\\nif len(ngram_0) != l_context:\\n    print(\"Errore!\")\\nelse:\\n    for _ in range(l_phrase):\\n        if ngram_0 in markov_dict:\\n            next_char=random.choice(markov_dict[ngram_0])\\n            phrase=phrase+next_char\\n            ngram_0=phrase[-l_context:]\\n        else:\\n            break #stoppo il ciclo\\nphrase\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ngram_0=\"sei pe\"\n",
    "l_phrase=100\n",
    "phrase=ngram_0\n",
    "if len(ngram_0) != l_context:\n",
    "    print(\"Errore!\")\n",
    "else:\n",
    "    for _ in range(l_phrase):\n",
    "        if ngram_0 in markov_dict:\n",
    "            next_char=random.choice(markov_dict[ngram_0])\n",
    "            phrase=phrase+next_char\n",
    "            ngram_0=phrase[-l_context:]\n",
    "        else:\n",
    "            break #stoppo il ciclo\n",
    "phrase\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a93735-2cc5-4115-9727-e0bfd354a977",
   "metadata": {},
   "source": [
    "fare una classe che implementi il metodo markoviano, con parametri privati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6520480-51cf-4912-9f9e-cfc3ff63cf8e",
   "metadata": {},
   "source": [
    "# Creazione della classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89ae13e-0233-43fd-b934-74d86f79eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoregressioneMarkoviano():\n",
    "    def __init__(self, file, l_context):\n",
    "        self.textFile=self.readFile(file)\n",
    "        self.markovDict=loadingDictionary(l_context)\n",
    "\n",
    "    def readFile(self, file):\n",
    "        #Caricamento input\n",
    "        file= open(\"./sei_personaggi_in_cerca_dautore_Luigi_Pirandello.txt\", \"r\", encoding=\"utf-8\")\n",
    "        text= file.read()\n",
    "\n",
    "        return self.clearFile(text)\n",
    "\n",
    "    def clearFile(self, text):\n",
    "        #Pre-processing\n",
    "        text= text.replace(\"\\n\", \" \").lower()\n",
    "        for _ in range(2):\n",
    "            text=text.replace(\"  \", \" \")\n",
    "\n",
    "        return text\n",
    "\n",
    "    def loadingDictionary(self, l_context):\n",
    "        for i, _ in enumerate(text[:-l_context]):  #scorre fino in fondo meno il numero di caratteri presi\n",
    "            ngram=text[i:i+l_context] #devo prendere il numero di lettere deciso(ngramma è una sequenza di lette)\n",
    "            #print(ngram)\n",
    "            if ngram in self.markov_dict:\n",
    "                self.markov_dict[ngram].append(text[i+l_context])\n",
    "            else:\n",
    "                self.markov_dict[ngram]=[text[i+l_context]]\n",
    "\n",
    "    def creationPhrase(self, ngram_0, l_phrase):\n",
    "        phrase=ngram_0\n",
    "        if len(ngram_0) != l_context:\n",
    "            print(\"Errore!\")\n",
    "        else:\n",
    "            for _ in range(l_phrase):\n",
    "                if ngram_0 in markov_dict:\n",
    "                    next_char=random.choice(markov_dict[ngram_0])\n",
    "                    phrase=phrase+next_char\n",
    "                    ngram_0=phrase[-l_context:]\n",
    "                else:\n",
    "                    break #stoppo il ciclo\n",
    "        return phrase\n",
    "\n",
    "    #mi manca l'aggiunta di un file al file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4e892-0a73-4a96-9526-4775efeb9292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
